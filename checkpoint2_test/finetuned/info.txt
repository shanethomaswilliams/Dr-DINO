[32mINFO    [0m [32m2024-11-24 18:11:53,661 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:11:53,661 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:11:53,666 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:11:53,667 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:11:53,667 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:11:53,667 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:11:53,668 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:11:53,668 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:11:57,081 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:11:57,115 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:11:57,118 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:11:57,128 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:11:57,130 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:11:58,399 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:14:33,285 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:14:33,285 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:14:33,289 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:14:33,290 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:14:33,290 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:14:33,290 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:14:33,290 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:14:33,290 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:14:36,748 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:14:36,781 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:14:36,784 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:14:36,796 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:14:36,797 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:14:37,404 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:16:55,036 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:16:55,036 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:16:55,041 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:16:55,042 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:16:55,042 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:16:55,042 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:16:55,042 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:16:55,043 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:16:58,438 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:16:58,470 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:16:58,473 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:16:58,484 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:16:58,486 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:16:59,060 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:18:55,966 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:18:55,966 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:18:55,971 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:18:55,972 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:18:55,972 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:18:55,972 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:18:55,972 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:18:55,973 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:18:59,343 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:18:59,376 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:18:59,379 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:18:59,390 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:18:59,392 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:18:59,953 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:21:06,025 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:21:06,025 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:21:06,030 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:21:06,030 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:21:06,031 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:21:06,031 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:21:06,031 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:21:06,031 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:21:09,164 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:21:09,195 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:21:09,198 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:21:09,208 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:21:09,210 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:21:09,780 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:21:39,974 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:21:39,974 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:21:39,979 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:21:39,979 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:21:39,979 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:21:39,979 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:21:39,980 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:21:39,980 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:21:42,655 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:21:42,687 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:21:42,690 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:21:42,701 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:21:42,703 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:21:43,263 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:23:31,980 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:23:31,980 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:23:31,985 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:23:31,986 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:23:31,987 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:23:31,987 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:23:31,987 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:23:31,987 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:23:35,083 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:23:35,114 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:23:35,117 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:23:35,128 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:23:35,129 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:23:35,694 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:25:41,122 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:25:41,123 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:25:41,127 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:25:41,128 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:25:41,128 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:25:41,128 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:25:41,129 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:25:41,129 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:25:44,257 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:25:44,288 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:25:44,291 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:25:44,302 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:25:44,303 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:25:44,872 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:26:25,408 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:26:25,409 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:26:25,413 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:26:25,414 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:26:25,414 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:26:25,414 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:26:25,414 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:26:25,415 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:26:28,148 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:26:28,178 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:26:28,181 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:26:28,192 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:26:28,193 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:26:28,739 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:27:06,399 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:27:06,399 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:27:06,404 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:27:06,405 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:27:06,405 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:27:06,405 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:27:06,405 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:27:06,406 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:27:09,504 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:27:09,535 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:27:09,538 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:27:09,549 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:27:09,550 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:27:10,107 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:28:58,229 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:28:58,229 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:28:58,233 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:28:58,234 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:28:58,234 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:28:58,234 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:28:58,235 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:28:58,235 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:29:01,567 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:29:01,600 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:29:01,603 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:29:01,614 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:29:01,616 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:29:02,166 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2024-11-24 18:33:30,577 | [34mgit:
  sha: c9730b3e16c7278974db0dd0a86b0a2514552aae, status: has uncommited changes, branch: initiating-open-grounding-dino
[0m
[32mINFO    [0m [32m2024-11-24 18:33:30,578 | [34mCommand: main.py --output_dir /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned -c /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py --datasets /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json --pretrain_model_path /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth --options text_encoder_type=/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights --eval[0m
[32mINFO    [0m [32m2024-11-24 18:33:30,582 | [34mFull config saved to /cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned/config_args_all.json[0m
[32mINFO    [0m [32m2024-11-24 18:33:30,583 | [34mworld size: 1[0m
[32mINFO    [0m [32m2024-11-24 18:33:30,583 | [34mrank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:33:30,583 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2024-11-24 18:33:30,583 | [34margs: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='swin_T_224_1k', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=2.0, config_file='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/cfg_odvg.py', dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], datasets='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/config/med_ft_test.json', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_backend='nccl', dist_url='env://', distributed=True, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=15, eval=True, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, focal_gamma=2.0, freeze_keywords=['bert'], frozen_weights=None, fusion_dropout=0.0, fusion_droppath=0.1, giou_loss_coef=2.0, gpu=0, hidden_dim=256, interm_loss_coef=1.0, label_list=['boneanomaly', 'bonelesion', 'foreignbody', 'fracture', 'metal', 'periostealreaction', 'pronatorsignsofttissue', 'text'], local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_drop=4, lr_drop_list=[4, 8], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', max_labels=50, max_text_len=256, modelname='groundingdino', multi_step_lr=False, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, note='', num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=8, onecyclelr=False, options={'text_encoder_type': '/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights'}, output_dir='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/checkpoint2_test/finetuned', param_dict_type='ddetr_in_mmdet', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/output/output-Nov-21-2024_04-35PM-job9665357/checkpoint_best_regular.pth', query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=1.0, set_cost_giou=2.0, start_epoch=0, sub_sentence_present=True, test=False, text_dropout=0.0, text_encoder_type='/cluster/tufts/cs152l3dclass/mprete01/Medical-Grounding-DINO/vanilla-weights/bert_weights', transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', use_checkpoint=True, use_coco_eval=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_ema=False, use_fusion_layer=True, use_text_cross_attention=True, use_text_enhancer=True, use_transformer_ckpt=True, weight_decay=0.0001, world_size=1)
[0m
[36mDEBUG   [0m [36m2024-11-24 18:33:30,584 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2024-11-24 18:33:33,577 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2024-11-24 18:33:33,608 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2024-11-24 18:33:33,611 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2024-11-24 18:33:33,622 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 49152,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 98304,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 196608,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 1769472,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 4608,
  "module.backbone.0.patch_embed.proj.bias": 96,
  "module.backbone.0.patch_embed.norm.weight": 96,
  "module.backbone.0.patch_embed.norm.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "module.backbone.0.layers.0.downsample.reduction.weight": 73728,
  "module.backbone.0.layers.0.downsample.norm.weight": 384,
  "module.backbone.0.layers.0.downsample.norm.bias": 384,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "module.backbone.0.layers.1.downsample.reduction.weight": 294912,
  "module.backbone.0.layers.1.downsample.norm.weight": 768,
  "module.backbone.0.layers.1.downsample.norm.bias": 768,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "module.backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "module.backbone.0.layers.2.downsample.norm.weight": 1536,
  "module.backbone.0.layers.2.downsample.norm.bias": 1536,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "module.backbone.0.norm1.weight": 192,
  "module.backbone.0.norm1.bias": 192,
  "module.backbone.0.norm2.weight": 384,
  "module.backbone.0.norm2.bias": 384,
  "module.backbone.0.norm3.weight": 768,
  "module.backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2024-11-24 18:33:33,623 | [34mbuild dataset ... ...[0m
[32mINFO    [0m [32m2024-11-24 18:33:34,173 | [34mIgnore keys: [][0m
